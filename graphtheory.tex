
\documentclass[12pt]{report}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
% package and document formatting stuff
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

% symbols and math stuff
\usepackage{amsmath,amsthm,amssymb}

% math operators
\usepackage{amsopn}

% script and caligraphics
\usepackage{eucal,mathrsfs}

% indexing
\usepackage{makeidx}

\usepackage{enumerate}

% formatting
\usepackage{fullpage}

% links and colors
\usepackage{color}
\usepackage[pdfstartview=FitH,
%             pdfauthor={\myauthor},
%             pdftitle={\mytitle},
            colorlinks,
            linkcolor=reference,
            citecolor=citation,
            urlcolor=e-mail,
            backref]{hyperref}
\usepackage[all]{xy}

\definecolor{todo}{rgb}{.80,.20,.20}
\definecolor{e-mail}{rgb}{0,.40,.80}
\definecolor{reference}{rgb}{.10,.40,.42}
\definecolor{mrnumber}{rgb}{.80,.40,0}
\definecolor{citation}{rgb}{0,.40,.80}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
% theorem stuff
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\theoremstyle{plain}

\newtheorem{thm}{Theorem}[section]
\newtheorem{defn}[thm]{Definition}
\newtheorem{deflem}[thm]{Definition/Lemma}
\newtheorem{notn}[thm]{Notation}
\newtheorem{convention}[thm]{Convention}
\newtheorem{lem}[thm]{Lemma}
\newtheorem{aside}[thm]{Aside}
\newtheorem{rem}[thm]{Remark}
\newtheorem{ex}[thm]{Example}
\newtheorem{facts}[thm]{Facts}
\newtheorem{cor}[thm]{Corollary}
\newtheorem{conj}[thm]{Conjecture}
\newtheorem{prop}[thm]{Proposition}

\newtheorem{exercise}[thm]{Exercise}
\newtheorem{question}[thm]{Question}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
% typography stuff
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\newcommand{\mb}[1]{\mathbf #1}
\newcommand{\mbb}[1]{\mathbb #1}
\newcommand{\mf}[1]{\mathfrak #1}
\newcommand{\mc}[1]{\mathcal #1}
\newcommand{\ms}[1]{\mathscr #1}
\newcommand{\mcu}[1]{\mathcu #1}
\newcommand{\oper}[1]{\operatorname{#1}}

\newcommand{\da}{\downarrow}
\newcommand{\ra}{\rightarrow}
\newcommand{\hra}{\hookrightarrow}
\newcommand{\dra}{\dashrightarrow}
\newcommand{\la}{\leftarrow}
\newcommand{\lra}{\longrightarrow}

\newcommand{\ov}{\overline}
\newcommand{\til}{\widetilde}
\newcommand{\wh}{\widehat}

\newcommand{\ZZ}{\mathbb{Z}}

\newcommand{\ann}{\oper{ann}}
\newcommand{\coker}{\oper{coker}}
\newcommand{\End}{\oper{End}}
\newcommand{\Aut}{\oper{Aut}}
\newcommand{\Stab}{\oper{Stab}}

\newcommand{\ind}{\oper{ind}}
\newcommand{\per}{\oper{per}}
\newcommand{\cores}{\oper{cor}}

\newcommand{\Br}{\oper{Br}}
\newcommand{\quat}[3]{
  \left(\begin{matrix} #1, #2 \\ #3
  \end{matrix}\right)
}
\newcommand{\symb}[3]{
  \left(#1, #2\right)_{#3}
}

\newcommand{\lcm}{\oper{lcm}}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
% other stuff
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\makeindex
\newcommand{\X}[1]{#1\index{#1}}
\newcommand{\Xb}[1]{\textbf{#1}\index{#1}}
\newcommand{\Ab}[2]{\textbf{#1}\index{#2}}

\newcommand{\todo}[1]{\textcolor{todo}{#1}}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
% end preamble
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\begin{document}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
% title stuff
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%


\author{Daniel Krashen}
\title{Graph Theory}

\maketitle
\tableofcontents

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
% document stuff
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\chapter*{Version Notes}
\addcontentsline{toc}{chapter}{Version Notes}

\section{Updates 1/28/2016}



\chapter{Lecture 1: The language of graphs}

\section{Graphs}
Graphs encode the idea of connections between things, for example
\begin{itemize}
\item networks of computers
\item people and their relationships
\item cities and highways
\item sets and intersections
\item workers and tasks
\end{itemize}


In formal mathematical terms, a graph is:
\begin{defn}
A \Xb{graph} $G$ is an ordered triple $(V, E, \psi)$ consisting of
\begin{itemize}
\item a finite, nonempty set $V$, whose elements are referred to as vertices,
\item a finite (possibly empty) set $E$, whose elements are referred to as
edges, and
\item an ``incidence'' function $\psi: E \to \ms R_2(V)$,
\end{itemize}
where $\ms R_2(V)$ is the set of unordered pairs of elements of $V$ (which
one may also think of as two elements multisubsets of $V$ -- see
Definition~\ref{multisubsets definition}).
\end{defn}

PICTURES AND EXAMPLES HERE

\begin{notn}
For a graph $G = (V, E, \psi)$ we write $V_G$ for $V$, $E_G$ for $E$ and
$\psi_G$ for $\psi$.
\end{notn}
In other words, using this notational convention, if we are given graphs
$G, H, K$, and have not specified letters for their sets of vertices,
edges, etcetera, we may write, for example, $E_K$ for the edges of the
graph $K$, $V_H$ for the vertices of $H$, and $\psi_G$ for the incidence
function of $G$.

\begin{defn}
Let $G$ be a graph, $e \in E_G$ an edge and $v \in V_G$ a vertex. We say
that $e$ and $v$ are \Xb{incident} if $v \in \psi(e)$.
\end{defn}

\begin{defn}
Let $G$ be a graph $v, w \in V_G$. We say that $v$ and $w$ are
\Xb{adjacent} if there is an edge $e$ with $v$ and $w$ incident to
$e$.
\end{defn}

\begin{defn}
Let $G$ be a graph $e, e' \in E_G$. We say that $e$ and $e'$ are
\Xb{adjacent} if there is a vertex $v$ with $e$ and $e'$ incident to
$v$.
\end{defn}

DIAGRAM

\begin{defn}
Let $G$ be a graph. If $e \in E_G$ is an edge, we say that $e$ is a
\Xb{loop}, if $e$ is incident to exactly one vertex.
\end{defn}

\begin{defn}
We say that $G$ is a \Xb{simple graph} if
\begin{itemize}
\item $G$ has no loops,
\item there is at most $1$ edge incident to any pair of vertices.
\end{itemize}
\end{defn}
Note that the second condition is the same as requiring that the function
$\psi_G$ be one-to-one.

Graphs can be drawn in many different ways:

\begin{defn}
$G$ is called a \Xb{planar graph} if it may be drawn in the plane with no
edges crossing.
\end{defn}

\section{Real world graph problems}

\subsection{Scheduling}
\begin{itemize}
\item vertices = jobs that need to be done
\item edges = jobs which require conflicting resources
\end{itemize}
problem: how to decide how many ``periods of work'' needed to complete
all jobs.

Similar problem: table arrangements at a wedding
\begin{itemize}
\item vertices = guests
\item edges = guest that don't get along
\end{itemize}
problem: how many tables?

translation: vertex colorings, chromatic number of a graph
\begin{defn}
A \Xb{vertex coloring} of a graph $G$ is a function $f$ defined on the set of
vertices of $G$. An vertex $n$-coloring is a function $f : V_G \to \{1,
\ldots, n\}$. We say that a vertex coloring is \Xb{proper}{proper!vertex
coloring} if $f(v) \neq f(w)$ for adjacent vertices $v, w$.
\end{defn}

\begin{defn}
The chromatic number of a graph, $\chi(G)$, is the minimal number $n$ such
that $G$ has a proper vertex $n$-coloring.
\end{defn}

\subsection{Tournaments}

various teams need to play each other. disjoint pairs of teams can play
simultaneously, but of course the same team can't play at the same time.
How many rounds are needed for teams to play each other?
\begin{itemize}
\item vertices = teams
\item edges = teams who need to play each other
\end{itemize}
problem: how many rounds?

\begin{defn}
An \Xb{edge coloring} of a graph $G$ is a function $f$ defined on the set of
edges of $G$. An edge $n$-coloring is a function $f : E_G \to \{1,
\ldots, n\}$. We say that an edge coloring is \Xb{proper}{proper!edge
coloring} if $f(e) \neq f(e')$ for adjacent vertices $e, e'$.
\end{defn}

\begin{defn}
The \Xb{edge chromatic number} of a graph, $\chi'(G)$, is the minimal
number $n$ such that $G$ has a proper edge $n$-coloring.
\end{defn}

\section{The rationale behind the language}

The choice of thinking of a graph as a triple $G = (V, E, \psi)$ has its
advantages and disadvantages. If we were only concerned with simple graphs,
we could have simplified our notation somewhat by omitting the function
$\psi$, and letting $E$ itself be a subset of the set of 
unordered pairs of distinct elements of $V$. In the case of general graphs,
however, where there can be multiple edges between two vertices, this is
somewhat less convenient. We could persist with this approach by saying
that $E$ be a multisubset instead of a subset, however, this is a little
bit less convenient later when we wish to talk about colorings or
labellings of edges.

An alternate way of defining things could be as follows: Instead of
defining the function $\psi$ as the fundamental concept, one may instead
define the notion of \textbf{incidence} as the fundamental concept as
follows:

\begin{defn}
A griph $G$ is an ordered triple $(V, E, \alpha)$ consisting of a set of
vertices $V$, a set of edges $E$, and a set of ordered pairs $\alpha
\subset V \times E$ such that \item for every $e \in E$, there is at least
one, and at most two elements $v \in V$ such that $(v, e) \in \alpha$. If
$(v, e) \in \alpha$, we say that $v$ is incident to $e$. A griph is called
simple if every edge is incident to exactly two vertices.
\end{defn}

\begin{exercise}
Show that griphs are exactly in correspondence with graphs in such a way
that the relationship of incidence lines up.
\end{exercise}

\section{Other basic notions}

For a graph $G$, we let $v(G) = \#V_G$ denote the number of vertices of
$G$, and $e(G) = \#E_G$ denote the number of edges of $G$. We let
$\delta(G)$ denote the mininum degree of a vertex of $G$, and $\Delta(G)$
denote the maximum degree of a vertex.

\chapter{Lecture 2: Digraphs and degree formulas}
\section{Directed graphs}

A variation on the notion of a graph is also very useful both theoretically
and in applications:

\begin{defn}
A \Xb{directed graph} or \Ab{digraph}{digraph|see {directed graph}} $D$ is an
ordered triple $(V, A, \psi)$ where $V$ is a set, referred to as the
\textbf{vertices} of $D$, a set $A$ referred to as the \Xb{arrows} of $D$,
and a pair of functions $s, t: A \to V$, taking arrows to
elements of $V$.
\end{defn}

\begin{notn}
For a digraph $D = (V, A, \psi)$, as before, we write $V_D$ for $V$, $A_D$
for $A$, $s_D$ for $s$, and $t_D$ for $t$.
\end{notn}

\begin{notn}
For a digraph $D$, and an arrow $a \in A_D$, we call $s(a)$ the
\Ab{source}{source (of an arrow)} of $a$ and $t(a)$ the \Ab{target}{target
(of an arrow)} of $a$.
\end{notn}

EXAMPLES:
\begin{itemize}
\item one way street maps
\item irreversible processes
\item dependencies: e.g. scheduling with dependencies
\end{itemize}

\newcommand{\outdeg}{\oper{outdeg}}
\newcommand{\indeg}{\oper{indeg}}

\begin{defn}
Let $D$ be a digraph. For a vertex $v$, we define the \Xb{outdegree} of
$v$, denoted $\outdeg v$, to be the number of edges whose source is $v$,
and the \Xb{indegree} of $v$, denoted $\indeg v$, to be the number of edges
whose target is $v$.
Formall, we have
\[ \outdeg v = \#\{a \in A_D \mid  s(a) = v\} ,\ \ 
\indeg v = \#\{a \in A_D \mid t(a) = v\}.
\]
If it is necessary to specify the digraph, we may also write $\outdeg_D(v)$
or $\indeg_D(v)$.
\end{defn}

\begin{prop}[The degree formula for digraphs]
Suppose that $D$ is a digraph. Then 
\[\sum_{v \in V_D} \outdeg(v) = \sum_{v \in V_D} \indeg(v) = \#A_D.\]
\end{prop}
\begin{proof}
Informally, this is clear for the following reason: every arrow in $A_D$
has its source at exactly one vertex, and so contributes exactly $1$ to the
first sum, and every arrow has its target at exactly one vertex and
similarly contributes exactly once to the second sum.

Let us, however, for the sake of practice, give a more formal argument:
\[\sum_{v \in V_D} \outdeg(v) = \sum_{v \in V_D} \sum_{a \in A_D, s(a) = v}
1 = \sum_{(v, a) \in V_D \times A_D, s(a) = v} 1 \]
But now, let us notice that the pairs $(v, a)$ with $s(a) = v$ are in
bijection with simply the set $A_D$, since by the description, $v$ is
determined by $a$. Therefore, we may rewrite this as:
\[\sum_{(v, a) \in V_D \times A_D, s(a) = v} 1  = \sum_{a \in A_D} 1 =
\#A_D.\]
The rest of the proof follows in an analogous way.

\end{proof}

\section{From graphs to digraphs}

Given a graph $G$, we may construct a digraph $dig(G)$ by definining
\begin{itemize}
\item $V_{dig(G)} = V_G$,
\item $A_{dig(G)} = \{(v, e) \in V \times E | v \in \psi(e)\}$,
\item $s_{dig(G)}(v, e) = v$, $t_{dig(G)}(v, e) = w$, where $\psi(e) = vw$.
\end{itemize}

\begin{defn}
Suppose that $G$ is a graph. We define the \Xb{degree} of a vertex $v \in
V_G$, denoted $\deg v$ to be the number of edges incident to $v$. If it is
necessary to specify the graph, we may also write $\deg_G v$.
\end{defn}

\begin{defn}
We say that a graph $G$ is $k$-\textbf{regular}\index{graph!regular} if every vertex of 
\end{defn}

\begin{prop}[The degree formula for graphs]
Suppose that $G$ is any graph. Then we have
\[\sum_{v \in V_G} \deg v = 2\#E.\]
\end{prop}
\begin{proof}
Intuitively, one way to see this is that if we chop each edge in the
middle, making two ``half edges'' for every edge, then each half edge is
incident to exactly one vertex, and contritutes exactly once to the degree
count on the left.

More formally, if we let $dig(G)$ be the associated digraph to $G$, then we
note that for every edge of $G$, there are two arrows of $dig(G)$. Also,
for every edge $e$ incident to $v$, there is exactly one arrow, which we
call $(v, e)$ which starts at $e$. That is, the map
\begin{align*}
\{e \in E_G | \text{$e$ is incident to $v$}\} &\to \{a \in A_{dig(G)} | s(a)
= v\} \\
e \mapsto (v, e) 
\end{align*}
is a bijection (its inverse being given by $(v, e) \mapsto e$). In
particular, this says that $\outdeg_{dig(G)} v = \deg_G v$.

By the
degree formula for digraphs, we therefore have
\[\sum_{v \in V_G} \deg_G v = \sum_{v \in A_{dig(G)}} \outdeg_{dig(G)} v =
\#A_{dig(G)} = 2\#E_G\]
as desired.
\end{proof}

A surprising conclusion here is that the sum of the degrees of the vertices
of a graph must be even! 

\chapter{Lecture 3: Subgraphs, isomorphisms}

\section{Isomorphisms}

\begin{defn}
Given two graphs $G, H$, an \Xb{isomorphism} $f$ from $G$ to $H$, written
$f: G \to H$ is a pair of maps $f = (f_V, f_E)$, where $f_V: V_G \to V_H$
is a function from the vertices of $G$ to the vertices of $H$ and $f_E: E_G
\to E_H$ is a function from the edges of $G$ to the edges of $H$ such that
both $f_V$ and $f_E$ are bijective and such that for $v \in V_G$, $e \in
E_G$, we have that $v$ and $e$ are incident if and only if $f_V(v)$ is
incident to $f_E(e)$.
\end{defn}

\begin{notn}
If $G$ and $H$ are graphs, we write $G \cong H$ and say that $G$ and $H$
are \textbf{isomorphic}\index{isomorphic graphs} if there exists an
isomorphism $f: G \to H$.
\end{notn}

In other words, thinking of the sets $V_G, E_G$ as the labels for the
vertices and edges of $G$ and thinking of $V_H, E_H$ as the labels for the
vertices and edges of $H$, we may think of $f_V$ and $f_E$ as re-assigning
the labels of the vertices and edges of a graph. The final property says
that the relation of incidence is preserved. Note that the incidence
relation encodes the function $\psi$, as $v$ and $e$ are incident if and
only if $v \in \psi(e)$ (and since the unordered pair/two element multiset
$\psi(e)$ is determined precisely by which elements it contains).

This is very useful, as our main concern is structural information about
graphs, as opposed to the specific names which we have assigned to their
edges and vertices.

\subsection{Simplifications for simple graphs}
It is perhaps useful to note that this definition may be made a bit simpler
in the case of simple graphs (not suprising, I'm sure). To be precise:

\begin{exercise}
Suppose that $G$ and $H$ are simple graphs. Suppose we have a bijective
function $g: V_G \to V_H$. Then there exists a unique graph isomorphism $f
= (f_V, f_E) : G \to E$ with $f_V = g$ if and only if for every two
vertices $v, w \in V_G$, we have that $v$ is adjacent to $w$ if and only if
$g(v)$ is adjacent to $g(w)$.
\end{exercise}

Expanding on this idea a bit, we see that in a simple graph, the graph is
determined up to isomorphism by the relationship of adjacency -- that is,
which vertices are joined by an edge. That is to say, although these two
graphs shown below are different as graphs:

TWO GRAPHS WITH THE SAME LABELS ON VERTICES BUT DIFFERENT LABELS ON EDGES,

they are still isomorphic in a canonical way. 

\begin{notn}
Along the same lines, for a
simple graph $G = (V, E, \psi)$, if $e$ is an edge with $\psi(e) = vw$, we
will abuse language and refer to $vw$ as $e$. In other words, the statement
that for a pair of vertices $v, w \in V$, $vw \in E$ means that there is
some edge $e$ with $\psi(e) = vw$, or equivalently $v$ and $w$ are
adjacent.
\end{notn}

\begin{defn}
For a simple graph $G$, we define the \textbf{complement}\index{complement
of a simple graph} $G$, denoted $\ov G$ to be the graph with the same set
of vertices (i.e. $V_G = V_{\ov G}$) and such that a pair of vertices $v,
w$ are adjacent in $\ov G$ if and only if they are \textit{not} adjacent in
$G$.
\end{defn}

\section{Subgraphs}

\begin{defn}
Let $G$ be a graph. We say that a graph $H$ is a \Xb{subgraph} of a graph
$G$ if $V_H \subset V_G$, $E_H \subset E_G$ and $\psi_H = \psi_G|_{E_H}$.
If $H$ is a subgraph of $G$, we write $H \subset G$.
\end{defn}

\begin{defn}
Let $G$ be a graph, and $W \subset V_G$ a subset of its vertices. We
define a new graph $G[W]$, called \textbf{the subgraph of $G$ induced by
$W$}\index{induced subgraph}, to be the graph whose vertex set is $W$ and
whose edge set $E_{G[W]}$ consists of all the edges of $G$ which are only
incident to vertices in $W$, together with the same incidence relations.
Formally, we set
\[ V_{G[W]} = W, \ E_{G[W]} = \{ e \in E_G \mid \psi(e) \subset W\}, \
\psi_{G[W]} = \psi|_{E_{G[W]}},\]
where $\psi|_{E_{G[W]}}$ denotes the restriction of the function $\psi$ to
the edges of $G[W]$.
\end{defn}

Given a graph $G$, we will often want to understand its structure by
looking at which subgraphs it has, and their properties. For example,
consider the following famous statement:

\begin{quote}
In every group of $6$ people, there is either a group of $3$ people all of
whom know each other, or a group of $3$ people, none of whom know each
other.
\end{quote}

One convenient way of conceptualizing this question within the framework of
graph theory is as follows: consider the two special graphs below

TRIANGLE   \ \ \ \ \ \ DISCRETE GRAPH WITH 3 VERTICES

We may now formally state the previous result as follows:

\begin{exercise}
Show that every simple graph with $6$ vertices must contain an induced
subgraph isomorphic to one of the above graphs\footnote{hint: as a first
step, considering
the friends of one particular person $A$, partitions the other $5$ people into
two groups (friends of $A$ and not friends of $A$), it follows that one of
these two groups must have at least $3$ people}.
\end{exercise}

In generalizing this result, which we will look into later in
Chapter~\ref{ramsey chapter}, it is natural to want to consider groups of
$n$ vertices in a graph, all of which are connected. The correponding
subgraphs of interest are called the complete graphs:

\begin{defn}
The \Xb{complete graph} on $n$ vertices, denoted $K_n$ is the simple graph
with vertices consisting of the set $\{1, \ldots, n\}$, and where every two
vertices are adjacent.
\end{defn}

\begin{defn}
Let $G$ be a simple graph. An $n$-\Xb{clique} in $G$ is a collection of
vertices $v_1, \ldots, v_n \in V_G$ such that the induced subgraph
$G[\{v_1, \ldots, v_n\}]$ is isomorphic to $K_n$.
\end{defn}

It is very natural to ask, for a given graph, about the existence or
non-existence of cliques of a given size.

\begin{exercise}
Find the smallest number $n$ such that every simple graph with $n$ edges
and $6$ vertices has a $3$-clique.
\end{exercise}

Another way to generalize the graph $K_3$ is in the notion of a cycle graph:
\begin{defn}
The \Xb{cycle graph} on $n$ vertices ($n \geq 3$)\footnote{we let bigons be
bigons, as they say}, denoted $C_n$ is the simple graph with vertices
consisting of the set $\{1, \ldots, n\}$, and where vertices $i$ and $j$
are adjacent if and only if $|i - j|$ is $1$ or $n-1$.
\end{defn}
In other words, there are edges between vertices which are $1$ unit apart,
and one additional edge connecting $1$ and $n$.

\begin{defn}
A cycle in a (not necessarily simple) graph $G$ is a subgraph $C \subset G$
such that $C \cong C_n$ for some $n \geq 3$.
\end{defn}

\begin{exercise}
Give an example of a simple graph with 4 vertices and exactly $3$ cycles, and a
graph with $3$ vertices and exactly $2$ cycles.
\end{exercise}

As we will see, cycles and cliques are interesting for a variety of
reasons, both practically and theoretically. Intuitively,
one should view the existence of cycles and cliques as helping to describe
how highly connected a graph is, somehow encapsulating ``redundancies of
connections.'' We will explore these ideas more in Chapters~\ref{bridges,
circuits, etc}.

\section{Unions, Intersections}

\begin{defn}
Let $G$ be a graph and $H_1, H_2$ sugraphs of $G$. We say that $G$ is the
\textbf{union}\index{union (of graphs)} of $H_1$ and $H_2$, and write $G = H_1
\cup H_2$ if $V_G = V_{H_1} \cup V_{H_2}$ and $E_G = E_{H_1} \cup
E_{H_2}$. We say that the union is \textbf{disjoint}\index{union!disjoint}
if $V_{H_1} \cap V_{H_2} = \emptyset$, and we say that the union is
\textbf{edge disjoint}\index{union!edge disjoint} if $E_{H_1} \cap
E_{H_2} = \emptyset$.
\end{defn}
Note that a disjoint union is automatically edge disjoint as well, since if
two subgraphs share a common edge it must also share any vertices which are
incident to it. Note also that whenever we have any two subgraphs $H_1,
H_2$ in a graph $G$, we may find a unique subgraph $H < G$ with $H = H_1
\cup H_2$. 

\begin{defn}
Let $G$ be a graph and $H_1, H_2 < G$ subgraphs of $G$. We define the
\textbf{intersection}\index{intersection (of graphs)} $H_1 \cap
H_2$ to be the subgraph with $V_{H_1 \cap H_2} = V_{H_1} \cap V_{H_2}$ and
$E_{H_1 \cap H_2} = E_{H_1} \cap E_{H_2}$. 
\end{defn}

\begin{exercise}
Verify that this definition does in fact give a well-defined subgraph of
$G$.
\end{exercise}

\section{Other operations on graphs}

\begin{defn}
Let $G$ be a graph, and $e \in E_G$. We define a subgraph $G - e$ of $G$ by
$V_{G - e} = V_G$ and $E_{G - e} = E_G \setminus \{e\}$.
\end{defn}

\begin{defn}
Let $G$ be a graph, and $v \in V_G$. We define the subgraph $G - v$ of $G$
to be the induced subgraph $G - v = G[V \setminus \{v \}$. That is, it is
the graph obtained by removing the vertex $v$ as well as all edges incident
to $v$.
\end{defn}

\chapter{Lecture 4: Paths, walks, trails, circuits, cycles}

\section{Walks and connectedness}

This chapter will introduce a fair amount of language which will be useful
in subsequent lectures. 

\begin{defn}
A \Xb{walk} $W$ in a graph $G$ is a sequence of alternating vertices and
edges
\[ W = v_1 e_2 v_2 e_3 v_3 \cdots e_n v_n \]
where $v_1, \ldots, v_n \in V_G$, $e_2, \ldots, e_n \in E_G$, and such that
$e_i$ is incident to the vertices $v_{i-1}$ and $v_i$. The vertex $v_1$ is
called the \textbf{origin}\index{origin (of a walk)} and $v_n$ is called
the \textbf{terminus}\index{terminus (of a walk)}.
\end{defn}

\begin{convention}
We will allow a walk to have only a single vertex. That is, the sequence
consisting only of a single vertex $v$ is a valid walk with origin and
terminus $v$. We will not allow a walk to be empty, however.
\end{convention}

\begin{notn}
It is easy to see that if $G$ is a simple graph, a walk $W = v_1 e_2 \cdots
e_n v_n$ is completely determined by its list of vertices. For this reason,
if $G$ is simple, we will generally write $W = v_1 v_2 \cdots v_n$ for
convenience.
\end{notn}

\begin{defn}
Let $G$ be a graph, $v, w \in V_G$. A $(v, w)$-walk is a walk with origin
$v$ and terminus $w$.
\end{defn}

\begin{defn}
Let $G$ be a graph, $W = v_1 e_2 \cdots e_n v_n$ and $W' = v_1' e_2' \cdots
e_m' v_m'$ walks with $v_n = v_1'$. We define the concatenation $WW'$ of
the two walks to be the $(v_1,v_m')$ walk defined by the sequence
\[v_1 e_2 \cdots e_n v_n e_2' v_2' \cdots e_m' v_m \]
\end{defn}

\begin{defn}
Let $G$ be a graph, and $W = v_1 e_2 \cdots e_n v_n$ a walk. We define the
reverse of $W$, denoted $W^{-1}$ to be the walk $v_n e_n v_{n-1} \cdots e_2
v_1$.
\end{defn}

\begin{exercise}
Define a relation on the vertices of a graph $G$ by saying that $v \sim w$
if and only if there exists a $(v, w)$-walk in $G$. Show that this gives an
equivalence relation.
\end{exercise}

In this way, we find that the set $V_G$ of vertices of $G$ can be written
as a disjoint union of equivalence classes $V_G = \bigcup_{i = 1}^n V_i$.

\begin{defn}
The induced subgraphs $G[V_i]$ are called the \Xb{components} of $G$. The
number $n$ of components of $G$ is denoted $c(G)$. We say that a graph $G$
is \Xb{connected} if it has a single component.
\end{defn}

Note that a graph is a disjoint union of its components, $G = \bigcup_{i =
1}^{c(G)} G[V_i]$.

\begin{exercise}
Show that $G$ is connected if and only if we cannot find nonempty subgraphs
$H_1, H_2$ such that $G$ is a disjoint union of $H_1$ and $H_2$.
\end{exercise}

\begin{exercise} \label{components exercise}
Somewhat more generally, show that 
\begin{enumerate}[1. ]
\item $c(G)$ is the maximum number such that
we may write $G$ as a disjoint union $G = \cup_{i = 1}^{c(G)} G_i$.
\item If we have $G = \cup_{i = 1}^n G_i$ a disjoint union, where each
subgraph $G_i$ is connected, then the $G_i$ are the connected components of
$G$ and $n = c(G)$. 
\end{enumerate}
\end{exercise}

\begin{exercise} \label{leaf doesn't change components}
Suppose $G$ is a graph and $v \in V_G$ with $\deg(v) = 1$. Then $c(G) = c(G
- v)$.
\end{exercise}

\subsection{Bridges}

\begin{defn}
We say that $e \in E_G$ is a bridge if $c(G - e) > c(G)$.
\end{defn}

\begin{lem} \label{components plus 1}
Suppose that $e$ is a bridge. Then $c(G - e) = c(G) + 1$.
\end{lem}
\begin{proof}
Let us begin with the case that $c(G) = 1$.  It is easy to see that if $e$
is a bridge, then it cannot be a loop.  In paticular, it is incident to two
distinct vertices $v_1, v_2$.  It is also clear that $e$ must be the unique
edge connecting its two incident vertices.  Let $G_1$ be the connected
component of $v_1$ in $G - e$ and $G_2$ be the connected component of $G_2$
in $G - e$. We claim that $G - e$ is the disjoint union of $G_1$ and $G_2$,
which would prove that $c(G) = 2$ as desired. 

First, we note that $G_1$ and $G_2$ are disjoint, since they consist of
vertices from distinct equivalence clases. Therefore, we need only to show
that every vertex and edge of $G - e$ is either in $G_1$ or $G_2$. 

Let us begin with the vertices. Let $w \in V_G = V_{G - e}$. By
Lemma~\ref{walk to path}, since $G$ is connected, we can find a $(w,
v_1)$-path in $G$.

If $v_2$ arises in this path, then looking at the first part of the path up
to $v_2$ gives a $(w, v_2)$-path in $G$ which does not involve the vertex
$v_1$. In particular, the edge $e$ cannot arise in this path. Therefore,
this path is actually a $(w, v_2)$-path within the connected component of
$v_2$ in $G - e$. That is, we have shown that $w \in V_2$. 

On the other hand, if $v_2$ doesn't arise in this path, the $(w, v_1)$-path
cannot involve the edge $e$, and in particular, shows that $w$ is in $V_1$.

Finally, we check that the every edge of $G - e$ is either in $G_1$ or
$G_2$. Given such an edge $e' \in E_{G - e}$, suppose $v$ is incident to
$e'$. By the above, $v$ is in $G_1$ or $G_2$. Let us suppose that $v \in
V_{G_1}$. Let $w$ be the other (not necessarily distinct) vertex incident
to $e$. We cannot have $w \in V_{G_2}$ since in this case we would have $w
\sim v$, but by definition, they are in different components. Therefore
both of the incident vertices for $e'$ lie in the same component $G_1$, and
by definition of the induced subgraph, the edge $e'$ is in $G_1$ as well.

To complete the proof, consider the case that $G$ may not be connected. In
this case, write $G = \bigcup_{i = 1}^{c(G)} G_i$ as a disjoint union of its
components (as in Exercise~\ref{components exercise}). Then the edge $e$
lies in some particular component, say $e \in G_1$. We have a disjoint
union:
\[ G - e = (G_1 - e) \cup \bigcup_{i = 2}^{c(G)} G_i, \]
and by the above, either $c(G_1 - e)$ is $1$ or $2$. If it is $1$, then
$G_1 - e$ is connected, and $c(G - e) = c(G)$ by Exercise~\ref{components
exercise}.  If it is $2$, then again by Exercise~\ref{components exercise},
we have $c(G - e) = c(G) + 1$.
\end{proof}

\section{Trails, paths, cycles, circuits}

\begin{defn}
A walk $W = v_1 e_2 v_2 \cdots e_n v_n$ in a graph $G$ is called a
\Xb{trail} if all the edges $e_i$ are distinct. It is called a \Xb{path} if
all the vertices $v_i$ are distinct.
\end{defn}
Note that paths are also nessarily trails.

\begin{lem}
Let $v, w$ be vertices of a graph $G$. Suppose that there is a $(v,w)$-walk
in $G$. Then there is a $(v,w)$-path in $G$.
\end{lem}
\begin{proof}
Suppose that $W = v_1 e_2 v_2 \cdots e_n v_n$ is a walk with $v_1 = v$ and
$v_n = w$. Choose $W$ of minimal length. We claim that $W$ is a path.
Supposing it is not, we would have $v_i = v_j$ for some $i < j$. But in
this case, we may consider the new walk $W' = v_1 e_2 \cdots e_{i-1}
v_{i-1} v_i e_{j+1} v_{j+1} \cdots e_n v_n$. By assumption, this is a
shorter walk, contradicting the minimality of $W$. Therefore $W$ is a path
as claimed.
\end{proof}

\begin{defn}
A walk is called \textbf{closed}\index{walk!closed} is its origin and
terminus coincide. A closed walk $W = v_1 e_2 v_2 \cdots e_n v_n e_{n+1}
v_1$ is called a \Xb{circuit} when $v_1 e_2 v_2 \cdots v_n$ is a trail,
and it is called a \Xb{cycle} when $v_1 e_2 v_2 \cdots v_n$ is a path.
\end{defn}

Note here that there is some notational ambiguity here, as we have defined
a cycle to both be a subgraph isomorphic to $C_n$, as well as a particular
type of walk. Of course the connection is that if $v_1 e_2 v_2 \cdots
e_{n+1} v_1$ is a cycle, then the vertices $v_1, v_2, \ldots, v_n$
together with the edges $e_2, e_3, \ldots, e_{n+1}$ give a subgraph isomorphic
to $C_n$.

\chapter{Lecture 5: Spanning subgraphs}

\begin{defn}
Let $H$ be a subgraph of $G$. We say that $H$ is a \Xb{spanning subgraph}
if $V_H = V_G$.
\end{defn}

In this lecture we will consider spanning subgraphs of various types. These
play a very important role for a variety of reasons.

\section{Trees}

\begin{defn}
We say that a simple graph $G$ is a \Xb{forest}, if it has no cycles; that
is, if it has no subgraphs which are isomorphic to $C_n$, $n \geq 3$.
\end{defn}

\begin{defn}
A \Xb{tree} is a connected forest.
\end{defn}

\begin{defn}
A vertex of degree $1$ in a tree is called a \Xb{leaf}.
\end{defn}


\begin{lem} \label{tree unique path}
A graph $G$ is a tree if and only if there is a unique $(v, w)$-path
between any two vertices.
\end{lem}

\begin{lem}
If $G$ is a tree then $e(G) + 1 = v(G)$.
\end{lem}
We will later see that the converse of this statement is true as well for a
connected graph.
\begin{proof}
Let us first show that this equality holds for all trees. Assuming first
that it doesn't, we may find a tree $T$ with a minimum number of edges such
that the equality doesn't hold. Of course, we can easily see that a
counterexample would have to have at least one edge $e$. Consider the new
graph $T - e$. This graph cannot be connected: if $v, w$ are the vertices
incident to $e$, then in $T$, since $v e w$ is a path from $v$ to $w$, it
is the unique one. But if $T -  e$ were connected, a $(v, w)$-path in $T -
e$ would give a $(v, w)$-path in $T$ which didn't involve $e$,
contradicting uniqueness.

We therefore have by Lemma~\ref{components plus 1} that $T - e$ is a
disjoint union of two connected graphs $T - e = T_1 \cup T_2$. Since $T -
e$ is acyclic, $T_1, T_2$ must be as well, and therefore they are both
trees. By assumption of minimality of $T$, it follows that we have $e(T_1)
+ 1 = v(T_1)$ and $e(T_2) + 1 = v(T_2)$. But therefore we have
\[ e(T) + 1 = \big(e(T_1) + e(T_2) + 1\big) + 1 = e(T_1) + 1 + e(T_2) +
1 = v(T_1) + v(T_2) = v(T) \]
as desired.
\end{proof}

\subsection{Spanning trees and Dijkstra's algorithm}

Consider the following problem. Given a list of cities $c_1, c_2, \ldots,
c_n$ and routes connecting certain cities, find the shortest route between
two given cities $c_i$ and $c_j$.

We can model this problem by letting the cities correspond to vertices of a
graph $G$, and by letting the routes be the edges. To keep track of
distances, we add the extra information of some ``cost function:''
\[ w: E_G \to \mathbb R_{\geq 0}\]

We may then ask the following question:
\begin{question}
Given vertices $v, w \in V_G$, how do we find the shortest path between $v$
an $w$.
\end{question}
In practical sitations, particularly when the number of cities and paths is
fairly large, it is not going to be effective to simply start listing paths
in a brute force way. One should also consider how the information of the
graph should be stored and accessed, for example on a computer. For
example, if we represent the graph as a triple, as we have previously
defined, this is not going to be particularly practical from the standpoint
of implementation. For example, suppose we are starting at a vertex $v$ and
would like to start constructing our path. We would first have to start to
look down our list of edges, and for every edge $e$, check and see whether
or not $v$ is incident to $e$, using the incidence function $\psi$. This is
a great deal of work to do for every edge in the graph. Instead, it would
be significantly more 
practical for this type of application to represent the graph as a list
of tuples $L_v = (v, (e_1, v_1), (e_2, v_2), \ldots, (e_n, v_n))$, where the
$e_i$ are the edges incident to $v$, and where $v, v_i$ are the vertices
incident to $e_i$. In this way, starting from a vertex $v$, would mean
starting with the list $L_v$, and being able to immediately access all
incident edges, and look up the corresponding adjacent vertex in order to
continue to build the path.

Let us not describe how to solve this problem. Starting from a vertex $v$,
if we are searching for paths to eventually get to $w$, we will, in the
process, successively build paths in various directions from $v$, finding
minimal length paths to various other vertices in the graph, until we
eventually reach our desired vertex $w$. In particular, the algorithm
really will construct minimal length paths from a fixed starting vertex $v$
to \textit{all} other vertices of the graph. We are free, however, to stop
the process once we have constructed a path to $w$.

How does this all relate to trees? Well, implicit in the process, we will
be constructing \textit{unique} paths from $v$ to every other vertex,
inductively. This will in fact result in building a spanning subgraph of
$G$ which will contain a unique path from $v$ to every other vertex. It
will follow quickly from Lemma~\ref{tree unique path}, that the resulting
spanning subgraph will in fact be a tree. In this way, one can see spanning
trees as giving maps of efficient ways to traverse a graph, from a fixed
starting point.

\subsubsection{the algorithm}

We will successsively build up a data set, which will consist of a list of
all vertices we have mapped minimal paths to, and the cost of the path.
We'll call this list $C$ and it will start with just the pair $(v, 0)$ --
the path from $v$ to $v$, consisting of no edges, has a cost of $0$. At
every step, we will let 
\begin{itemize}
\item
$S \subset V_G$ denote the set of vertices arising
in $C$, whose cost has been calculated, 
\item $S^c$ will be the complement of
$S$ in $V_G$
\item $N = \{ v' \in S^c \mid \text{ $v$ is adjacent to some $u \in S$}\}$.
\end{itemize}

We proceed as follows:
\begin{enumerate} [ 1. ]
\item choose 
\end{enumerate}

\section{Regular graphs}

\begin{defn}
A graph $G$ is called $k$-\Xb{regular} if every vertex $v \in V_G$ has
degree $k$.
\end{defn}

Let's examine $k$ regular simple graphs for small values of $k$. For example, a
$0$-regular graph is graph with no edges (just isolated vertices).

A connected $1$-regular graph is easily seen to consist just of two
vertices joined by a single edge. It follows that a general $1$-regular
graph, being a disjoint union of its components. It follows that for a
graph $G$, a $1$-regular spanning subgraph $H$ corresponds to what is
called a \Xb{matching}, namely, a way of writing the set of vertices $V_G$
as a disjoint union $V_G = \bigcup P_i$ where each $P_i$ is a pair of
distinct adjacent vertices. 

\begin{lem}
A connected $2$-regular simple graph is isomorphic to a cycle graph $C_n$
for some $n$.
\end{lem}

\begin{defn}
A Hamiltonian cycle in a graph $G$ is a cycle which passes through each
vertex of $G$.
\end{defn}

We see that a connected $2$-regular spanning subgraph of a graph $G$,
corresponds to a Hamiltonian cycle. 

\appendix

\chapter{Foundational notions}

\section{Sets and multisets}

The substructure of the majority of modern mathematics is set theory. It
therefore would behoove us to take a very slight digression into some
useful concepts and notations.

\begin{defn}
A \Xb{set} is a collection of elements, is defined exactly by its elements.
Two sets are equal if they contain the same elements.
\end{defn}

\begin{notn}
We will denote a set using ``set notation.'' This consists of listing the
elements of a set enclosed in braces, and separated by commas. Note that
the order in which elements are written doesen't change the set. For
example $\{a, b, c\} = \{b, c, a\}$.
\end{notn}

\begin{defn}
For a set $S$, its \Xb{power set} $\ms P(S)$, is the set whose
elements are the subsets of $S$
\end{defn}

\begin{defn}
For a set $S$, we let $\ms P_k(S)$ denote its subsets with exactly $k$
elements.
\end{defn}

\begin{defn}
For sets $S, T$ we let $S \times T$ denote the set whose elements are
ordered pairs $(s, t)$ where $s \in S$ and $t \in T$.
\end{defn}

\begin{defn}
A \Xb{multiset} $\ms S$ is a pair $(S, m)$, where $S$ is a set, and $m$ is a
function $m: S \to \mathbb Z_{> 0}$ from $S$ to the positive integers. For
$s \in S$, we refer to $m(s)$ as the multiplicity of $s$ in $\ms S$. We
write $s \in \ms S$. We call $S$ the underlying set of $\ms S$.

For a multiset $\ms S = (S, m)$, we will use the notation $m_{\ms S}$ to
refer to $m$.
\end{defn}

\begin{notn}
We will write a multiset $S$ by writing a list of its elements, with
repetition, in a string, each elements arising in the string as many times
as it its multiplicity. The order in which the elements are written
doesen't matter. For example, $abbbcc = abcbcb$.
\end{notn}

\begin{defn}
Let $\ms S$ and $\ms T$ be multisets. We say that $\ms S \subset \ms T$ if
the underlying set of $\ms S$ is contained in the underlying set of $\ms
T$.
\end{defn}

If $S$ is a set, we will also identify $S$ with the multiset $(S, m)$
defined by $m(s) = 1$ for each $s \in S$ (that is, $S$ contains each of its
elements exactly $1$ time).

These mutisets are occasionally useful in combinatorics to think of the
idea of sampling with replacement/repetition.

\begin{defn}
If $\ms S = (S, m)$ is a multiset, we define the \Xb{cardinality} of $\ms
S$, denoted  $\#\ms S$, to be
\[ \sum_{s \in S} m(s). \]
\end{defn}
In particular, considering a set $T$ as a multiset as described above, we
have $\# T$ is exactly the number of elements of $T$.

\begin{defn} \label{multisubsets definition}
Let $S$ be a set. We write $\ms R(S)$ to denote the set of all mulisubsets
of $S$, and $\ms R_k(S)$ the set of all multisubsets of $S$ with
cardinality exactly $S$.
\end{defn}


\section{Relations}

\begin{defn}
Recall that if $X, Y$ are sets, a \Xb{relation} (from $X$ to $Y$) is a
subset $R \subset X \times Y$ of the product of $X$ and $Y$. If an ordered
pair $(x, y) \in R$ we say that $x$ is related to $y$ and write $xRy$.
\end{defn}

\begin{notn}
Frequently we will talk about a relation \textit{on a set $X$}. This this
is shorthand for a relation $R \subset X \times X$ from $X$ to iteself.
\end{notn}

Two important types of relations are \Xb{functions} and \Xb{equivalence
relations}, which we now describe.

\subsection{Functions}

\begin{defn}
A function from $X$ to $Y$ is a relation $f \subset X \times Y$ such that
for every $x \in X$ there is exactly one $y \in Y$ such that $xfy$. 
\end{defn}

\begin{notn}
If $f$ is a function from $x$ to $y$, we write $f(x)$ to denote the unique
$y \in Y$ such that $xfy$.
\end{notn}

\subsection{Equivalence Relations}

\begin{defn}
Let $R$ be a relation on $X$. We say that $R$ is an \textbf{equivalence
relation}, if the following properties hold
\begin{enumerate}
\item(\textit{reflexivity})
  for every $x \in X$, we have $xRx$,
\item(\textit{symmetry})
  for every $x, y \in X$, we have $xRy$ if and only if $yRx$,
\item(\textit{transitivity})
  for every $x, y, z \in X$, whenever $xRy$ and $yRz$ we must also
  have $xRz$.
\end{enumerate}
\end{defn}

%\bibliographystyle{alpha}
%\bibliography{citations}
\printindex

\end{document}
