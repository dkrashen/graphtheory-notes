
\documentclass[12pt]{report}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
% package and document formatting stuff
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

% symbols and math stuff
\usepackage{amsmath,amsthm,amssymb}

% math operators
\usepackage{amsopn}

% script and caligraphics
\usepackage{eucal,mathrsfs}

% indexing
\usepackage{makeidx}

\usepackage{enumerate}

% formatting
\usepackage{fullpage}

% links and colors
\usepackage{color}
\usepackage[pdfstartview=FitH,
%             pdfauthor={\myauthor},
%             pdftitle={\mytitle},
            colorlinks,
            linkcolor=reference,
            citecolor=citation,
            urlcolor=e-mail,
            backref]{hyperref}
\usepackage[all]{xy}

\definecolor{todo}{rgb}{.80,.20,.20}
\definecolor{e-mail}{rgb}{0,.40,.80}
\definecolor{reference}{rgb}{.10,.40,.42}
\definecolor{mrnumber}{rgb}{.80,.40,0}
\definecolor{citation}{rgb}{0,.40,.80}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
% theorem stuff
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\theoremstyle{plain}

\newtheorem{thm}{Theorem}[section]
\newtheorem{defn}[thm]{Definition}
\newtheorem{deflem}[thm]{Definition/Lemma}
\newtheorem{notn}[thm]{Notation}
\newtheorem{lem}[thm]{Lemma}
\newtheorem{aside}[thm]{Aside}
\newtheorem{rem}[thm]{Remark}
\newtheorem{ex}[thm]{Example}
\newtheorem{facts}[thm]{Facts}
\newtheorem{cor}[thm]{Corollary}
\newtheorem{conj}[thm]{Conjecture}
\newtheorem{prop}[thm]{Proposition}

\newtheorem{exercise}[thm]{Exercise}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
% typography stuff
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\newcommand{\mb}[1]{\mathbf #1}
\newcommand{\mbb}[1]{\mathbb #1}
\newcommand{\mf}[1]{\mathfrak #1}
\newcommand{\mc}[1]{\mathcal #1}
\newcommand{\ms}[1]{\mathscr #1}
\newcommand{\mcu}[1]{\mathcu #1}
\newcommand{\oper}[1]{\operatorname{#1}}

\newcommand{\da}{\downarrow}
\newcommand{\ra}{\rightarrow}
\newcommand{\hra}{\hookrightarrow}
\newcommand{\dra}{\dashrightarrow}
\newcommand{\la}{\leftarrow}
\newcommand{\lra}{\longrightarrow}

\newcommand{\ov}{\overline}
\newcommand{\til}{\widetilde}
\newcommand{\wh}{\widehat}

\newcommand{\ZZ}{\mathbb{Z}}

\newcommand{\ann}{\oper{ann}}
\newcommand{\coker}{\oper{coker}}
\newcommand{\End}{\oper{End}}
\newcommand{\Aut}{\oper{Aut}}
\newcommand{\Stab}{\oper{Stab}}

\newcommand{\ind}{\oper{ind}}
\newcommand{\per}{\oper{per}}
\newcommand{\cores}{\oper{cor}}

\newcommand{\Br}{\oper{Br}}
\newcommand{\quat}[3]{
  \left(\begin{matrix} #1, #2 \\ #3
  \end{matrix}\right)
}
\newcommand{\symb}[3]{
  \left(#1, #2\right)_{#3}
}

\newcommand{\lcm}{\oper{lcm}}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
% other stuff
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\makeindex
\newcommand{\X}[1]{#1\index{#1}}
\newcommand{\Xb}[1]{\textbf{#1}\index{#1}}
\newcommand{\Ab}[2]{\textbf{#1}\index{#2}}

\newcommand{\todo}[1]{\textcolor{todo}{#1}}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
% end preamble
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\begin{document}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
% title stuff
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%


\author{Daniel Krashen}
\title{Graph Theory}

\maketitle
\tableofcontents

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
% document stuff
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%


\chapter{Lecture 1: The language of graphs}

\section{Graphs}
Graphs encode the idea of connections between things, for example
\begin{itemize}
\item networks of computers
\item people and their relationships
\item cities and highways
\item sets and intersections
\item workers and tasks
\end{itemize}


In formal mathematical terms, a graph is:
\begin{defn}
A \Xb{graph} $G$ is an ordered triple $(V, E, \psi)$ consisting of
\begin{itemize}
\item a set $V$, whose elements are referred to as vertices,
\item a set $E$, whose elements are referred to as edges, and
\item an ``incidence'' function $\psi: E \to \ms R_2(V)$,
\end{itemize}
where $\ms R_2(V)$ is the set of unordered pairs of elements of $V$ (which
one may also think of as two elements multisubsets of $V$ -- see
Definition~\ref{multisubsets definition}).
\end{defn}

PICTURES AND EXAMPLES HERE

\begin{notn}
For a graph $G = (V, E, \psi)$ we write $V_G$ for $V$, $E_G$ for $E$ and
$\psi_G$ for $\psi$.
\end{notn}
In other words, using this notational convention, if we are given graphs
$G, H, K$, and have not specified letters for their sets of vertices,
edges, etcetera, we may write, for example, $E_K$ for the edges of the
graph $K$, $V_H$ for the vertices of $H$, and $\psi_G$ for the incidence
function of $G$.

\begin{defn}
Let $G$ be a graph, $e \in E_G$ an edge and $v \in V_G$ a vertex. We say
that $e$ and $v$ are \Xb{incident} if $v \in \psi(e)$.
\end{defn}

\begin{defn}
Let $G$ be a graph $v, w \in V_G$. We say that $v$ and $w$ are
\Xb{adjacent} if there is an edge $e$ with both $v$ and $w$ incident to
$e$.
\end{defn}

DIAGRAM

\begin{defn}
Let $G$ be a graph. If $e \in E_G$ is an edge, we say that $e$ is a
\Xb{loop}, if $e$ is incident to exactly one vertex.
\end{defn}

\begin{defn}
We say that $G$ is a \Xb{simple graph} if
\begin{itemize}
\item $G$ has no loops,
\item there is at most $1$ edge incident to any pair of vertices.
\end{itemize}
\end{defn}
Note that the second condition is the same as requiring that the function
$\psi_G$ be one-to-one.

Graphs can be drawn in many different ways:

\begin{defn}
$G$ is called a \Xb{planar graph} if it may be drawn in the plane with no
edges crossing.
\end{defn}

\section{Real world graph problems}

\subsection{Scheduling}
\begin{itemize}
\item vertices = jobs that need to be done
\item edges = jobs which require conflicting resources
\end{itemize}
problem: how to decide how many ``periods of work'' needed to complete
all jobs.

Similar problem: table arrangements at a wedding
\begin{itemize}
\item vertices = guests
\item edges = guest that don't get along
\end{itemize}
problem: how many tables?

translation: vertex colorings, chromatic number of a graph

\subsection{Tournaments}

various teams need to play each other. disjoint pairs of teams can play
simultaneously, but of course the same team can't play at the same time.
How many rounds are needed for teams to play each other?
\begin{itemize}
\item vertices = teams
\item edges = teams who need to play each other
\end{itemize}
problem: how many rounds?

\section{The rationale behind the language}

The choice of thinking of a graph as a triple $G = (V, E, \psi)$ has its
advantages and disadvantages. If we were only concerned with simple graphs,
we could have simplified our notation somewhat by omitting the function
$\psi$, and letting $E$ itself be a subset of the set of 
unordered pairs of distinct elements of $V$. In the case of general graphs,
however, where there can be multiple edges between two vertices, this is
somewhat less convenient. We could persist with this approach by saying
that $E$ be a multisubset instead of a subset, however, this is a little
bit less convenient later when we wish to talk about colorings or
labellings of edges.

An alternate way of defining things could be as follows: Instead of
defining the function $\psi$ as the fundamental concept, one may instead
define the notion of \textbf{incidence} as the fundamental concept as
follows:

\begin{defn}
A griph $G$ is an ordered triple $(V, E, \alpha)$ consisting of a set of
vertices $V$, a set of edges $E$, and a set of ordered pairs $\alpha
\subset V \times E$ such that \item for every $e \in E$, there is at least
one, and at most two elements $v \in V$ such that $(v, e) \in \alpha$. If
$(v, e) \in \alpha$, we say that $v$ is incident to $e$. A griph is called
simple if every edge is incident to exactly two vertices.
\end{defn}

\begin{exercise}
Show that griphs are exactly in correspondence with graphs in such a way
that the relationship of incidence lines up.
\end{exercise}

\chapter{Lecture 2: Digraphs and degree formulas}
\section{Directed graphs}

A variation on the notion of a graph is also very useful both theoretically
and in applications:

\begin{defn}
A \Xb{directed graph} or \Ab{digraph}{digraph|see {directed graph}} $D$ is an
ordered triple $(V, A, \psi)$ where $V$ is a set, referred to as the
\textbf{vertices} of $D$, a set $A$ referred to as the \Xb{arrows} of $D$,
and a pair of functions $s, t: A \to V$, taking arrows to
elements of $V$.
\end{defn}

\begin{notn}
For a digraph $D = (V, A, \psi)$, as before, we write $V_D$ for $V$, $A_D$
for $A$, $s_D$ for $s$, and $t_D$ for $t$.
\end{notn}

\begin{notn}
For a digraph $D$, and an arrow $a \in A_D$, we call $s(a)$ the
\Ab{source}{source (of an arrow)} of $a$ and $t(a)$ the \Ab{target}{target
(of an arrow)} of $a$.
\end{notn}

EXAMPLES:
\begin{itemize}
\item one way street maps
\item irreversible processes
\item dependencies: e.g. scheduling with dependencies
\end{itemize}

\newcommand{\outdeg}{\oper{outdeg}}
\newcommand{\indeg}{\oper{indeg}}

\begin{defn}
Let $D$ be a digraph. For a vertex $v$, we define the \Xb{outdegree} of
$v$, denoted $\outdeg v$, to be the number of edges whose source is $v$,
and the \Xb{indegree} of $v$, denoted $\indeg v$, to be the number of edges
whose target is $v$.
Formall, we have
\[ \outdeg v = \#\{a \in A_D \mid  s(a) = v\} ,\ \ 
\indeg v = \#\{a \in A_D \mid t(a) = v\}.
\]
If it is necessary to specify the digraph, we may also write $\outdeg_D(v)$
or $\indeg_D(v)$.
\end{defn}

\begin{prop}[The degree formula for digraphs]
Suppose that $D$ is a digraph. Then 
\[\sum_{v \in V_D} \outdeg(v) = \sum_{v \in V_D} \indeg(v) = \#A_D.\]
\end{prop}
\begin{proof}
Informally, this is clear for the following reason: every arrow in $A_D$
has its source at exactly one vertex, and so contributes exactly $1$ to the
first sum, and every arrow has its target at exactly one vertex and
similarly contributes exactly once to the second sum.

Let us, however, for the sake of practice, give a more formal argument:
\[\sum_{v \in V_D} \outdeg(v) = \sum_{v \in V_D} \sum_{a \in A_D, s(a) = v}
1 = \sum_{(v, a) \in V_D \times A_D, s(a) = v} 1 \]
But now, let us notice that the pairs $(v, a)$ with $s(a) = v$ are in
bijection with simply the set $A_D$, since by the description, $v$ is
determined by $a$. Therefore, we may rewrite this as:
\[\sum_{(v, a) \in V_D \times A_D, s(a) = v} 1  = \sum_{a \in A_D} 1 =
\#A_D.\]
The rest of the proof follows in an analogous way.

\end{proof}

\section{From graphs to digraphs}

Given a graph $G$, we may construct a digraph $dig(G)$ by definining
\begin{itemize}
\item $V_{dig(G)} = V_G$,
\item $A_{dig(G)} = \{(v, e) \in V \times E | v \in \psi(e)\}$,
\item $s_{dig(G)}(v, e) = v$, $t_{dig(G)}(v, e) = w$, where $\psi(e) = vw$.
\end{itemize}

\begin{defn}
Suppose that $G$ is a graph. We define the \Xb{degree} of a vertex $v \in
V_G$, denoted $\deg v$ to be the number of edges incident to $v$. If it is
necessary to specify the graph, we may also write $\deg_G v$.
\end{defn}

\begin{defn}
We say that a graph $G$ is $k$-\textbf{regular}\index{graph!regular} if every vertex of 
\end{defn}

\begin{prop}[The degree formula for graphs]
Suppose that $G$ is any graph. Then we have
\[\sum_{v \in V_G} \deg v = 2\#E.\]
\end{prop}
\begin{proof}
Intuitively, one way to see this is that if we chop each edge in the
middle, making two ``half edges'' for every edge, then each half edge is
incident to exactly one vertex, and contritutes exactly once to the degree
count on the left.

More formally, if we let $dig(G)$ be the associated digraph to $G$, then we
note that for every edge of $G$, there are two arrows of $dig(G)$. Also,
for every edge $e$ incident to $v$, there is exactly one arrow, which we
call $(v, e)$ which starts at $e$. That is, the map
\begin{align*}
\{e \in E_G | \text{$e$ is incident to $v$}\} &\to \{a \in A_{dig(G)} | s(a)
= v\} \\
e \mapsto (v, e) 
\end{align*}
is a bijection (its inverse being given by $(v, e) \mapsto e$). In
particular, this says that $\outdeg_{dig(G)} v = \deg_G v$.

By the
degree formula for digraphs, we therefore have
\[\sum_{v \in V_G} \deg_G v = \sum_{v \in A_{dig(G)}} \outdeg_{dig(G)} v =
\#A_{dig(G)} = 2\#E_G\]
as desired.
\end{proof}

A surprising conclusion here is that the sum of the degrees of the vertices
of a graph must be even! 

\chapter{Lecture 3: Subgraphs, isomorphisms}

\section{Isomorphisms}

\begin{defn}
Given two graphs $G, H$, an \Xb{isomorphism} $f$ from $G$ to $H$, written
$f: G \to H$ is a pair of maps $f = (f_V, f_E)$, where $f_V: V_G \to V_H$
is a function from the vertices of $G$ to the vertices of $H$ and $f_E: E_G
\to E_H$ is a function from the edges of $G$ to the edges of $H$ such that
both $f_V$ and $f_E$ are bijective and such that for $v \in V_G$, $e \in
E_G$, we have that $v$ and $e$ are incident if and only if $f_V(v)$ is
incident to $f_E(e)$.
\end{defn}

\begin{notn}
If $G$ and $H$ are graphs, we write $G \cong H$ and say that $G$ and $H$
are \textbf{isomorphic}\index{isomorphic graphs} if there exists an
isomorphism $f: G \to H$.
\end{notn}

In other words, thinking of the sets $V_G, E_G$ as the labels for the
vertices and edges of $G$ and thinking of $V_H, E_H$ as the labels for the
vertices and edges of $H$, we may think of $f_V$ and $f_E$ as re-assigning
the labels of the vertices and edges of a graph. The final property says
that the relation of incidence is preserved. Note that the incidence
relation encodes the function $\psi$, as $v$ and $e$ are incident if and
only if $v \in \psi(e)$ (and since the unordered pair/two element multiset
$\psi(e)$ is determined precisely by which elements it contains).

This is very useful, as our main concern is structural information about
graphs, as opposed to the specific names which we have assigned to their
edges and vertices.

\subsection{Simplifications for simple graphs}
It is perhaps useful to note that this definition may be made a bit simpler
in the case of simple graphs (not suprising, I'm sure). To be precise:

\begin{exercise}
Suppose that $G$ and $H$ are simple graphs. Suppose we have a bijective
function $g: V_G \to V_H$. Then there exists a unique graph isomorphism $f
= (f_V, f_E) : G \to E$ with $f_V = g$ if and only if for every two
vertices $v, w \in V_G$, we have that $v$ is adjacent to $w$ if and only if
$g(v)$ is adjacent to $g(w)$.
\end{exercise}

Expanding on this idea a bit, we see that in a simple graph, the graph is
determined up to isomorphism by the relationship of adjacency -- that is,
which vertices are joined by an edge. That is to say, although these two
graphs shown below are different as graphs:

TWO GRAPHS WITH THE SAME LABELS ON VERTICES BUT DIFFERENT LABELS ON EDGES,

they are still isomorphic in a canonical way. 

\begin{notn}
Along the same lines, for a
simple graph $G = (V, E, \psi)$, if $e$ is an edge with $\psi(e) = vw$, we
will abuse language and refer to $vw$ as $e$. In other words, the statement
that for a pair of vertices $v, w \in V$, $vw \in E$ means that there is
some edge $e$ with $\psi(e) = vw$, or equivalently $v$ and $w$ are
adjacent.
\end{notn}

\section{Subgraphs}

\begin{defn}
Let $G$ be a graph. We say that a graph $H$ is a \Xb{subgraph} of a graph
$G$ if $V_H \subset V_G$, $E_H \subset E_G$ and $\psi_H = \psi_G|_{E_H}$.
If $H$ is a subgraph of $G$, we write $H \subset G$.
\end{defn}

\begin{defn}
Let $G$ be a graph, and $W \subset V_G$ a subset of its vertices. We
define a new graph $G[W]$, called \textbf{the subgraph of $G$ induced by
$W$}\index{induced subgraph}, to be the graph whose vertex set is $W$ and
whose edge set $E_{G[W]}$ consists of all the edges of $G$ which are only
incident to vertices in $W$, together with the same incidence relations.
Formally, we set
\[ V_{G[W]} = W, \ E_{G[W]} = \{ e \in E_G \mid \psi(e) \subset W\}, \
\psi_{G[W]} = \psi|_{E_{G[W]}},\]
where $\psi|_{E_{G[W]}}$ denotes the restriction of the function $\psi$ to
the edges of $G[W]$.
\end{defn}

Given a graph $G$, we will often want to understand its structure by
looking at which subgraphs it has, and their properties. For example,
consider the following famous statement:

\begin{quote}
In every group of $6$ people, there is either a group of $3$ people all of
whom know each other, or a group of $3$ people, none of whom know each
other.
\end{quote}

One convenient way of conceptualizing this question within the framework of
graph theory is as follows: consider the two special graphs below

TRIANGLE   \ \ \ \ \ \ DISCRETE GRAPH WITH 3 VERTICES

We may now formally state the previous result as follows:

\begin{exercise}
Show that every simple graph with $6$ vertices must contain an induced
subgraph isomorphic to one of the above graphs\footnote{hint: as a first
step, considering
the friends of one particular person $A$, partitions the other $5$ people into
two groups (friends of $A$ and not friends of $A$), it follows that one of
these two groups must have at least $3$ people}.
\end{exercise}

In generalizing this result, which we will look into later in
Chapter~\ref{ramsey chapter}, it is natural to want to consider groups of
$n$ vertices in a graph, all of which are connected. The correponding
subgraphs of interest are called the complete graphs:

\begin{defn}
The \Xb{complete graph} on $n$ vertices, denoted $K_n$ is the simple graph
with vertices consisting of the set $\{1, \ldots, n\}$, and where every two
vertices are adjacent.
\end{defn}

\begin{defn}
Let $G$ be a simple graph. An $n$-\Xb{clique} in $G$ is a collection of
vertices $v_1, \ldots, v_n \in V_G$ such that the induced subgraph
$G[\{v_1, \ldots, v_n\}]$ is isomorphic to $K_n$.
\end{defn}

It is very natural to ask, for a given graph, about the existence or
non-existence of cliques of a given size.

\begin{exercise}
Find the smallest number $n$ such that every simple graph with $n$ edges
and $6$ vertices has a $3$-clique.
\end{exercise}

Another way to generalize the graph $K_3$ is in the notion of a cycle graph:
\begin{defn}
The \Xb{cycle graph} on $n$ vertices ($n \geq 3$)\footnote{we let bigons be
bigons, as they say}, denoted $C_n$ is the simple graph with vertices
consisting of the set $\{1, \ldots, n\}$, and where vertices $i$ and $j$
are adjacent if and only if $|i - j|$ is $1$ or $n-1$.
\end{defn}
In other words, there are edges between vertices which are $1$ unit apart,
and one additional edge connecting $1$ and $n$.

\begin{defn}
A cycle in a (not necessarily simple) graph $G$ is a subgraph $C \subset G$
such that $C \cong C_n$ for some $n \geq 3$.
\end{defn}

\begin{exercise}
Give an example of a simple graph with 4 vertices and exactly $3$ cycles, and a
graph with $3$ vertices and exactly $2$ cycles.
\end{exercise}

As we will see, cycles and cliques are interesting for a variety of
reasons, both practically and theoretically. Intuitively,
one should view the existence of cycles and cliques as helping to describe
how highly connected a graph is, somehow encapsulating ``redundancies of
connections.'' We will explore these ideas more in Chapters~\ref{bridges,
circuits, etc}.

\section{Unions, Intersections}

\begin{defn}
Let $G$ be a graph and $H_1, H_2$ sugraphs of $G$. We say that $G$ is the
\textbf{union}\index{union (of graphs)} of $H_1$ and $H_2$, and write $G = H_1
\cup H_2$ if $V_G = V_{H_1} \cup V_{H_2}$ and $E_G = E_{H_1} \cup
E_{H_2}$. We say that the union is \textbf{disjoint}\index{union!disjoint}
if $V_{H_1} \cap V_{H_2} = \emptyset$, and we say that the union is
\textbf{edge disjoint}\index{union!edge disjoint} if $E_{H_1} \cap
E_{H_2} = \emptyset$.
\end{defn}
Note that a disjoint union is automatically edge disjoint as well, since if
two subgraphs share a common edge it must also share any vertices which are
incident to it. Note also that whenever we have any two subgraphs $H_1,
H_2$ in a graph $G$, we may find a unique subgraph $H < G$ with $H = H_1
\cup H_2$. 

\begin{defn}
Let $G$ be a graph and $H_1, H_2 < G$ subgraphs of $G$. We define the
\textbf{intersection}\index{intersection (of graphs)} $H_1 \cap
H_2$ to be the subgraph with $V_{H_1 \cap H_2} = V_{H_1} \cap V_{H_2}$ and
$E_{H_1 \cap H_2} = E_{H_1} \cap E_{H_2}$. 
\end{defn}

\begin{exercise}
Verify that this definition does in fact give a well-defined subgraph of
$G$.
\end{exercise}

\chapter{Lecture 4: Paths, walks, trails, circuits, cycles}

This chapter will introduce a fair amount of language which will be useful
in subsequent lectures. 

\begin{defn}
walk: sequence of vertices and edges (or just vertices if simple)
\end{defn}

concatenation, inversion, $(v, w)$-walk

connectedness

\begin{exercise}
Define a relation on the vertices of a graph $G$ by saying that $v \sim w$
if and only if there exists a $(v, w)$-walk in $G$. Show that this gives an
equivalece relation.
\end{exercise}

\begin{defn}
connected component
\end{defn}

\appendix

\chapter{Foundational notions}

\section{Sets and multisets}

The substructure of the majority of modern mathematics is set theory. It
therefore would behoove us to take a very slight digression into some
useful concepts and notations.

\begin{defn}
A \Xb{set} is a collection of elements, is defined exactly by its elements.
Two sets are equal if they contain the same elements.
\end{defn}

\begin{notn}
We will denote a set using ``set notation.'' This consists of listing the
elements of a set enclosed in braces, and separated by commas. Note that
the order in which elements are written doesen't change the set. For
example $\{a, b, c\} = \{b, c, a\}$.
\end{notn}

\begin{defn}
For a set $S$, its \Xb{power set} $\ms P(S)$, is the set whose
elements are the subsets of $S$
\end{defn}

\begin{defn}
For a set $S$, we let $\ms P_k(S)$ denote its subsets with exactly $k$
elements.
\end{defn}

\begin{defn}
For sets $S, T$ we let $S \times T$ denote the set whose elements are
ordered pairs $(s, t)$ where $s \in S$ and $t \in T$.
\end{defn}

\begin{defn}
A \Xb{multiset} $\ms S$ is a pair $(S, m)$, where $S$ is a set, and $m$ is a
function $m: S \to \mathbb Z_{> 0}$ from $S$ to the positive integers. For
$s \in S$, we refer to $m(s)$ as the multiplicity of $s$ in $\ms S$. We
write $s \in \ms S$. We call $S$ the underlying set of $\ms S$.

For a multiset $\ms S = (S, m)$, we will use the notation $m_{\ms S}$ to
refer to $m$.
\end{defn}

\begin{notn}
We will write a multiset $S$ by writing a list of its elements, with
repetition, in a string, each elements arising in the string as many times
as it its multiplicity. The order in which the elements are written
doesen't matter. For example, $abbbcc = abcbcb$.
\end{notn}

\begin{defn}
Let $\ms S$ and $\ms T$ be multisets. We say that $\ms S \subset \ms T$ if
the underlying set of $\ms S$ is contained in the underlying set of $\ms
T$.
\end{defn}

If $S$ is a set, we will also identify $S$ with the multiset $(S, m)$
defined by $m(s) = 1$ for each $s \in S$ (that is, $S$ contains each of its
elements exactly $1$ time).

These mutisets are occasionally useful in combinatorics to think of the
idea of sampling with replacement/repetition.

\begin{defn}
If $\ms S = (S, m)$ is a multiset, we define the \Xb{cardinality} of $\ms
S$, denoted  $\#\ms S$, to be
\[ \sum_{s \in S} m(s). \]
\end{defn}
In particular, considering a set $T$ as a multiset as described above, we
have $\# T$ is exactly the number of elements of $T$.

\begin{defn} \label{multisubsets definition}
Let $S$ be a set. We write $\ms R(S)$ to denote the set of all mulisubsets
of $S$, and $\ms R_k(S)$ the set of all multisubsets of $S$ with
cardinality exactly $S$.
\end{defn}


\section{Relations}

\begin{defn}
Recall that if $X, Y$ are sets, a \Xb{relation} (from $X$ to $Y$) is a
subset $R \subset X \times Y$ of the product of $X$ and $Y$. If an ordered
pair $(x, y) \in R$ we say that $x$ is related to $y$ and write $xRy$.
\end{defn}

\begin{notn}
Frequently we will talk about a relation \textit{on a set $X$}. This this
is shorthand for a relation $R \subset X \times X$ from $X$ to iteself.
\end{notn}

Two important types of relations are \Xb{functions} and \Xb{equivalence
relations}, which we now describe.

\subsection{Functions}

\begin{defn}
A function from $X$ to $Y$ is a relation $f \subset X \times Y$ such that
for every $x \in X$ there is exactly one $y \in Y$ such that $xfy$. 
\end{defn}

\begin{notn}
If $f$ is a function from $x$ to $y$, we write $f(x)$ to denote the unique
$y \in Y$ such that $xfy$.
\end{notn}

\subsection{Equivalence Relations}

\begin{defn}
Let $R$ be a relation on $X$. We say that $R$ is an \textbf{equivalence
relation}, if the following properties hold
\begin{enumerate}
\item(\textit{reflexivity})
  for every $x \in X$, we have $xRx$,
\item(\textit{symmetry})
  for every $x, y \in X$, we have $xRy$ if and only if $yRx$,
\item(\textit{transitivity})
  for every $x, y, z \in X$, whenever $xRy$ and $yRz$ we must also
  have $xRz$.
\end{enumerate}
\end{defn}

\iffalse
\chapter{Subgraphs, new graphs from old}

\chapter{Proofs and formality}

\chapter{Spanning subgraphs and applications}

\fi
%\bibliographystyle{alpha}
%\bibliography{citations}
\printindex

\end{document}
